{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from PIL import Image\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    gpu = 0\n",
    "DIM = 64 # Model dimensionality\n",
    "BATCH_SIZE = 1 # Batch size\n",
    "CRITIC_ITERS = 5 # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
    "ITERS = 200000 # How many generator iterations to train for\n",
    "OUTPUT_DIM = 250000 # Number of pixels in MNIST (28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(dataset=Dataset('train'), batch_size=1, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=Dataset('test'), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(DIM)\n",
    "netD = Discriminator(DIM)\n",
    "# print(netG)\n",
    "# print(netD)\n",
    "if use_cuda:\n",
    "    netD = netD.cuda(gpu)\n",
    "    netG = netG.cuda(gpu)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "if use_cuda:\n",
    "    one = one.cuda(gpu)\n",
    "    mone = mone.cuda(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(ITERS):\n",
    "    start_time = time.time()\n",
    "    ############################\n",
    "    # (1) Update D network\n",
    "    ###########################\n",
    "    for p in netD.parameters():  # reset requires_grad\n",
    "        p.requires_grad = True  # they are set to False below in netG update\n",
    "\n",
    "    for iter_d in xrange(CRITIC_ITERS):\n",
    "        _data = data.next()\n",
    "        real_data = torch.Tensor(_data)\n",
    "        if use_cuda:\n",
    "            real_data = real_data.cuda(gpu)\n",
    "        real_data_v = autograd.Variable(real_data)\n",
    "\n",
    "        netD.zero_grad()\n",
    "\n",
    "        # train with real\n",
    "        D_real = netD(real_data_v)\n",
    "        D_real = D_real.mean()\n",
    "        # print D_real\n",
    "        D_real.backward(mone)\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(BATCH_SIZE, 128)\n",
    "        if use_cuda:\n",
    "            noise = noise.cuda(gpu)\n",
    "        noisev = autograd.Variable(noise, volatile=True)  # totally freeze netG\n",
    "        fake = autograd.Variable(netG(noisev).data)\n",
    "        inputv = fake\n",
    "        D_fake = netD(inputv)\n",
    "        D_fake = D_fake.mean()\n",
    "        D_fake.backward(one)\n",
    "\n",
    "        # train with gradient penalty\n",
    "        gradient_penalty = calc_gradient_penalty(netD, real_data_v.data, fake.data)\n",
    "        gradient_penalty.backward()\n",
    "\n",
    "        D_cost = D_fake - D_real + gradient_penalty\n",
    "        Wasserstein_D = D_real - D_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "    ############################\n",
    "    # (2) Update G network\n",
    "    ###########################\n",
    "    for p in netD.parameters():\n",
    "        p.requires_grad = False  # to avoid computation\n",
    "    netG.zero_grad()\n",
    "\n",
    "    noise = torch.randn(BATCH_SIZE, 128)\n",
    "    if use_cuda:\n",
    "        noise = noise.cuda(gpu)\n",
    "    noisev = autograd.Variable(noise)\n",
    "    fake = netG(noisev)\n",
    "    G = netD(fake)\n",
    "    G = G.mean()\n",
    "    G.backward(mone)\n",
    "    G_cost = -G\n",
    "    optimizerG.step()\n",
    "\n",
    "\n",
    "    # Calculate dev loss and generate samples every 100 iters\n",
    "    if iteration % 100 == 99:\n",
    "        dev_disc_costs = []\n",
    "        for images,_ in dev_gen():\n",
    "            imgs = torch.Tensor(images)\n",
    "            if use_cuda:\n",
    "                imgs = imgs.cuda(gpu)\n",
    "            imgs_v = autograd.Variable(imgs, volatile=True)\n",
    "\n",
    "            D = netD(imgs_v)\n",
    "            _dev_disc_cost = -D.mean().cpu().data.numpy()\n",
    "            dev_disc_costs.append(_dev_disc_cost)\n",
    "\n",
    "        generate_image(iteration, netG)\n",
    "\n",
    "    # Write logs every 100 iters\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
